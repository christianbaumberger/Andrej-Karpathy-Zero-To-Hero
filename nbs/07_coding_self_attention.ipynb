{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding and Coding the Self-Attention Mechanism of Large Language Models From Scrath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Life', 'is', 'short', 'eat', 'dessert', 'first']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentence = \"Life is short, eat dessert first\"\n",
    "word_list = input_sentence.replace(\",\", \"\").split()\n",
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 6\n",
      "{'Life': 0, 'dessert': 1, 'eat': 2, 'first': 3, 'is': 4, 'short': 5}\n"
     ]
    }
   ],
   "source": [
    "stoi = {s:i for i,s in enumerate(sorted(word_list))}\n",
    "vocab_size = len(stoi)\n",
    "print(f\"vocab size: {vocab_size}\")\n",
    "print(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 4, 5, 2, 1, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentence_int = torch.tensor([stoi[s] for s in word_list])\n",
    "input_sentence_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 16])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "embedding_size = 16\n",
    "embed = torch.nn.Embedding(vocab_size, embedding_size)\n",
    "embed.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 16])\n",
      "tensor([ 0.3374, -0.1778, -0.3035, -0.5880,  0.3486,  0.6603, -0.2196, -0.3792,\n",
      "         0.7671, -1.1925,  0.6984, -1.4097,  0.1794,  1.8951,  0.4954,  0.2692])\n"
     ]
    }
   ],
   "source": [
    "embedded_input_sentence = embed(input_sentence_int).detach()\n",
    "print(embedded_input_sentence.shape)\n",
    "print(embedded_input_sentence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = embedding_size\n",
    "d_q = d_k = 24\n",
    "d_v = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 16]) torch.Size([24, 16]) torch.Size([28, 16])\n"
     ]
    }
   ],
   "source": [
    "W_query = torch.nn.Parameter(torch.rand(d_q, d))\n",
    "W_key = torch.nn.Parameter(torch.rand(d_k, d))\n",
    "W_value = torch.nn.Parameter(torch.rand(d_v, d))\n",
    "print(W_query.shape, W_key.shape, W_value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24]) torch.Size([24]) torch.Size([28])\n"
     ]
    }
   ],
   "source": [
    "x_2 = embedded_input_sentence[1]\n",
    "query_2 = W_query @ x_2\n",
    "key_2 = W_key @ x_2\n",
    "value_2 = W_value @ x_2\n",
    "\n",
    "print(query_2.shape, key_2.shape, value_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 24]) torch.Size([6, 28])\n"
     ]
    }
   ],
   "source": [
    "keys = (W_key @ embedded_input_sentence.T).T\n",
    "values = (W_value @ embedded_input_sentence.T).T\n",
    "\n",
    "print(keys.shape, values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13.1208, grad_fn=<DotBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omega_24 = query_2.dot(keys[4])\n",
    "omega_24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  2.1938,  -3.8873,  14.7953,   2.0779,  13.1208, -13.5755],\n",
      "       grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "omega_2 = query_2 @ keys.T\n",
    "print(omega_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0405, 0.0117, 0.5301, 0.0395, 0.3766, 0.0016],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "attention_weights_2 = F.softmax(omega_2 * d_k**-0.5, dim=0)\n",
    "print(attention_weights_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6]), torch.Size([6, 28]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights_2.shape, values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28])\n",
      "tensor([-1.5785, -2.1954, -2.2932, -2.2415, -1.2018, -1.1000, -1.4869, -1.8232,\n",
      "        -2.7236, -1.0135, -2.6909, -1.2424, -2.0749, -2.5979, -1.8763, -0.2468,\n",
      "        -1.7071, -1.6958, -1.7728, -2.4239, -3.8261, -2.3653, -2.9899, -1.8056,\n",
      "        -0.1843, -0.8150, -1.0318, -3.1751], grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "context_vector_2 = attention_weights_2 @ values\n",
    "print(context_vector_2.shape)\n",
    "print(context_vector_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 3\n",
    "multihead_W_query = torch.nn.Parameter(torch.rand(h, d_q, d))\n",
    "multihead_W_key = torch.nn.Parameter(torch.rand(h, d_k, d))\n",
    "multihead_W_value = torch.nn.Parameter(torch.rand(h, d_v, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 24, 16]), torch.Size([16]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multihead_W_query.shape, x_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 24])\n"
     ]
    }
   ],
   "source": [
    "multihead_query_2 = multihead_W_query @ x_2\n",
    "print(multihead_query_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 24]), torch.Size([3, 28]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multihead_key_2 = multihead_W_key @ x_2\n",
    "multihead_value_2 = multihead_W_value @ x_2\n",
    "multihead_key_2.shape, multihead_value_2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 24, 16]), torch.Size([6, 16]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multihead_W_key.shape, embedded_input_sentence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 24, 6])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(multihead_W_key @ embedded_input_sentence.T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 24, 6]) torch.Size([3, 28, 6])\n"
     ]
    }
   ],
   "source": [
    "multihead_keys = multihead_W_key @ embedded_input_sentence.T\n",
    "multihead_values = multihead_W_value @ embedded_input_sentence.T\n",
    "print(multihead_keys.shape, multihead_values.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: within the Transformer model, the second sentence comes from the encoder, while the sentence for the queries comes from the decoder\n",
    "embedded_input_sentence_2 = torch.rand(8, 16) # 2nd input sequence\n",
    "\n",
    "keys = (W_key @ embedded_input_sentence_2.T).T\n",
    "values = (W_value @ embedded_input_sentence_2.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24]) torch.Size([8, 24]) torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "omega_2 = query_2 @ keys.T\n",
    "print(query_2.shape, keys.shape, omega_2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_weights_2 = F.softmax(omega_2 * d_k**-0.5, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28])\n",
      "tensor([4.3351, 3.6771, 4.2762, 3.9791, 4.1577, 3.2921, 3.7612, 4.4088, 3.5626,\n",
      "        3.6418, 4.6238, 5.4345, 3.6379, 4.6668, 4.2885, 3.2560, 5.3845, 4.0421,\n",
      "        3.4744, 3.7277, 4.6168, 3.8642, 4.3314, 4.7715, 3.5523, 3.3344, 5.0613,\n",
      "        3.8946], grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "context_vector_2 = attention_weights_2 @ values\n",
    "print(context_vector_2.shape)\n",
    "print(context_vector_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
